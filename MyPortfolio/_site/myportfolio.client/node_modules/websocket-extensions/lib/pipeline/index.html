<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

<!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Extension pipelining | portfolio</title>
<meta name="generator" content="Jekyll v3.9.3" />
<meta property="og:title" content="Extension pipelining" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="http://localhost:4000/myportfolio.client/node_modules/websocket-extensions/lib/pipeline/" />
<meta property="og:url" content="http://localhost:4000/myportfolio.client/node_modules/websocket-extensions/lib/pipeline/" />
<meta property="og:site_name" content="portfolio" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Extension pipelining" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","headline":"Extension pipelining","url":"http://localhost:4000/myportfolio.client/node_modules/websocket-extensions/lib/pipeline/"}</script>
<!-- End Jekyll SEO tag -->

    <link rel="stylesheet" href="/assets/css/style.css?v=059dd2210d8f0fb8d42af0cbb5c1b29e59b98886">
    <!-- start custom head snippets, customize with your own _includes/head-custom.html file -->

<!-- Setup Google Analytics -->



<!-- You can set your favicon here -->
<!-- link rel="shortcut icon" type="image/x-icon" href="/favicon.ico" -->

<!-- end custom head snippets -->

  </head>
  <body>
    <div class="container-lg px-3 my-5 markdown-body">
      
      <h1><a href="http://localhost:4000/">portfolio</a></h1>
      

      <h1 id="extension-pipelining">Extension pipelining</h1>

<p><code class="language-plaintext highlighter-rouge">websocket-extensions</code> models the extension negotiation and processing pipeline
of the WebSocket protocol. Between the driver parsing messages from the TCP
stream and handing those messages off to the application, there may exist a
stack of extensions that transform the message somehow.</p>

<p>In the parlance of this framework, a <em>session</em> refers to a single instance of an
extension, acting on a particular socket on either the server or the client
side. A session may transform messages both incoming to the application and
outgoing from the application, for example the <code class="language-plaintext highlighter-rouge">permessage-deflate</code> extension
compresses outgoing messages and decompresses incoming messages. Message streams
in either direction are independent; that is, incoming and outgoing messages
cannot be assumed to ‘pair up’ as in a request-response protocol.</p>

<p>Asynchronous processing of messages poses a number of problems that this
pipeline construction is intended to solve.</p>

<h2 id="overview">Overview</h2>

<p>Logically, we have the following:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>+-------------+  out  +---+     +---+     +---+       +--------+
|             |------&gt;|   |----&gt;|   |----&gt;|   |------&gt;|        |
| Application |       | A |     | B |     | C |       | Driver |
|             |&lt;------|   |&lt;----|   |&lt;----|   |&lt;------|        |
+-------------+  in   +---+     +---+     +---+       +--------+

                      \                       /
                       +----------o----------+
                                  |
                               sessions
</code></pre></div></div>

<p>For outgoing messages, the driver receives the result of</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    C.outgoing(B.outgoing(A.outgoing(message)))

or, [A, B, C].reduce(((m, ext) =&gt; ext.outgoing(m)), message)
</code></pre></div></div>

<p>For incoming messages, the application receives the result of</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    A.incoming(B.incoming(C.incoming(message)))

or, [C, B, A].reduce(((m, ext) =&gt; ext.incoming(m)), message)
</code></pre></div></div>

<p>A session is of the following type, to borrow notation from pseudo-Haskell:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>type Session = {
  incoming :: Message -&gt; Message
  outgoing :: Message -&gt; Message
  close    :: () -&gt; ()
}
</code></pre></div></div>

<p>(That <code class="language-plaintext highlighter-rouge">() -&gt; ()</code> syntax is intended to mean that <code class="language-plaintext highlighter-rouge">close()</code> is a nullary void
method; I apologise to any Haskell readers for not using the right monad.)</p>

<p>The <code class="language-plaintext highlighter-rouge">incoming()</code> and <code class="language-plaintext highlighter-rouge">outgoing()</code> methods perform message transformation in the
respective directions; <code class="language-plaintext highlighter-rouge">close()</code> is called when a socket closes so the session
can release any resources it’s holding, for example a DEFLATE de/compression
context.</p>

<p>However because this is JavaScript, the <code class="language-plaintext highlighter-rouge">incoming()</code> and <code class="language-plaintext highlighter-rouge">outgoing()</code> methods
may be asynchronous (indeed, <code class="language-plaintext highlighter-rouge">permessage-deflate</code> is based on <code class="language-plaintext highlighter-rouge">zlib</code>, whose API
is stream-based). So their interface is strictly:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>type Session = {
  incoming :: Message -&gt; Callback -&gt; ()
  outgoing :: Message -&gt; Callback -&gt; ()
  close    :: () -&gt; ()
}

type Callback = Either Error Message -&gt; ()
</code></pre></div></div>

<p>This means a message <em>m2</em> can be pushed into a session while it’s still
processing the preceding message <em>m1</em>. The messages can be processed
concurrently but they <em>must</em> be given to the next session in line (or to the
application) in the same order they came in. Applications will expect to receive
messages in the order they arrived over the wire, and sessions require this too.
So ordering of messages must be preserved throughout the pipeline.</p>

<p>Consider the following highly simplified extension that deflates messages on the
wire. <code class="language-plaintext highlighter-rouge">message</code> is a value conforming the type:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>type Message = {
  rsv1   :: Boolean
  rsv2   :: Boolean
  rsv3   :: Boolean
  opcode :: Number
  data   :: Buffer
}
</code></pre></div></div>

<p>Here’s the extension:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">var</span> <span class="nx">zlib</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="dl">'</span><span class="s1">zlib</span><span class="dl">'</span><span class="p">);</span>

<span class="kd">var</span> <span class="nx">deflate</span> <span class="o">=</span> <span class="p">{</span>
  <span class="na">outgoing</span><span class="p">:</span> <span class="kd">function</span><span class="p">(</span><span class="nx">message</span><span class="p">,</span> <span class="nx">callback</span><span class="p">)</span> <span class="p">{</span>
    <span class="nx">zlib</span><span class="p">.</span><span class="nx">deflateRaw</span><span class="p">(</span><span class="nx">message</span><span class="p">.</span><span class="nx">data</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">error</span><span class="p">,</span> <span class="nx">result</span><span class="p">)</span> <span class="p">{</span>
      <span class="nx">message</span><span class="p">.</span><span class="nx">rsv1</span> <span class="o">=</span> <span class="kc">true</span><span class="p">;</span>
      <span class="nx">message</span><span class="p">.</span><span class="nx">data</span> <span class="o">=</span> <span class="nx">result</span><span class="p">;</span>
      <span class="nx">callback</span><span class="p">(</span><span class="nx">error</span><span class="p">,</span> <span class="nx">message</span><span class="p">);</span>
    <span class="p">});</span>
  <span class="p">},</span>

  <span class="na">incoming</span><span class="p">:</span> <span class="kd">function</span><span class="p">(</span><span class="nx">message</span><span class="p">,</span> <span class="nx">callback</span><span class="p">)</span> <span class="p">{</span>
    <span class="c1">// decompress inbound messages (elided)</span>
  <span class="p">},</span>

  <span class="na">close</span><span class="p">:</span> <span class="kd">function</span><span class="p">()</span> <span class="p">{</span>
    <span class="c1">// no state to clean up</span>
  <span class="p">}</span>
<span class="p">};</span>
</code></pre></div></div>

<p>We can call it with a large message followed by a small one, and the small one
will be returned first:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">var</span> <span class="nx">crypto</span> <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="dl">'</span><span class="s1">crypto</span><span class="dl">'</span><span class="p">),</span>
    <span class="nx">large</span>  <span class="o">=</span> <span class="nx">crypto</span><span class="p">.</span><span class="nx">randomBytes</span><span class="p">(</span><span class="mi">1</span> <span class="o">&lt;&lt;</span> <span class="mi">14</span><span class="p">),</span>
    <span class="nx">small</span>  <span class="o">=</span> <span class="k">new</span> <span class="nx">Buffer</span><span class="p">(</span><span class="dl">'</span><span class="s1">hi</span><span class="dl">'</span><span class="p">);</span>

<span class="nx">deflate</span><span class="p">.</span><span class="nx">outgoing</span><span class="p">({</span> <span class="na">data</span><span class="p">:</span> <span class="nx">large</span> <span class="p">},</span> <span class="kd">function</span><span class="p">()</span> <span class="p">{</span>
  <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="dl">'</span><span class="s1">large</span><span class="dl">'</span><span class="p">);</span>
<span class="p">});</span>

<span class="nx">deflate</span><span class="p">.</span><span class="nx">outgoing</span><span class="p">({</span> <span class="na">data</span><span class="p">:</span> <span class="nx">small</span> <span class="p">},</span> <span class="kd">function</span><span class="p">()</span> <span class="p">{</span>
  <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="dl">'</span><span class="s1">small</span><span class="dl">'</span><span class="p">);</span>
<span class="p">});</span>

<span class="cm">/* prints:  2 'small'
            1 'large' */</span>
</code></pre></div></div>

<p>So a session that processes messages asynchronously may fail to preserve message
ordering.</p>

<p>Now, this extension is stateless, so it can process messages in any order and
still produce the same output. But some extensions are stateful and require
message order to be preserved.</p>

<p>For example, when using <code class="language-plaintext highlighter-rouge">permessage-deflate</code> without <code class="language-plaintext highlighter-rouge">no_context_takeover</code> set,
the session retains a DEFLATE de/compression context between messages, which
accumulates state as it consumes data (later messages can refer to sections of
previous ones to improve compression). Reordering parts of the DEFLATE stream
will result in a failed decompression. Messages must be decompressed in the same
order they were compressed by the peer in order for the DEFLATE protocol to
work.</p>

<p>Finally, there is the problem of closing a socket. When a WebSocket is closed by
the application, or receives a closing request from the other peer, there may be
messages outgoing from the application and incoming from the peer in the
pipeline. If we close the socket and pipeline immediately, two problems arise:</p>

<ul>
  <li>We may send our own closing frame to the peer before all prior messages we
sent have been written to the socket, and before we have finished processing
all prior messages from the peer</li>
  <li>The session may be instructed to close its resources (e.g. its de/compression
context) while it’s in the middle of processing a message, or before it has
received messages that are upstream of it in the pipeline</li>
</ul>

<p>Essentially, we must defer closing the sessions and sending a closing frame
until after all prior messages have exited the pipeline.</p>

<h2 id="design-goals">Design goals</h2>

<ul>
  <li>Message order must be preserved between the protocol driver, the extension
sessions, and the application</li>
  <li>Messages should be handed off to sessions and endpoints as soon as possible,
to maximise throughput of stateless sessions</li>
  <li>The closing procedure should block any further messages from entering the
pipeline, and should allow all existing messages to drain</li>
  <li>Sessions should be closed as soon as possible to prevent them holding memory
and other resources when they have no more messages to handle</li>
  <li>The closing API should allow the caller to detect when the pipeline is empty
and it is safe to continue the WebSocket closing procedure</li>
  <li>Individual extensions should remain as simple as possible to facilitate
modularity and independent authorship</li>
</ul>

<p>The final point about modularity is an important one: this framework is designed
to facilitate extensions existing as plugins, by decoupling the protocol driver,
extensions, and application. In an ideal world, plugins should only need to
contain code for their specific functionality, and not solve these problems that
apply to all sessions. Also, solving some of these problems requires
consideration of all active sessions collectively, which an individual session
is incapable of doing.</p>

<p>For example, it is entirely possible to take the simple <code class="language-plaintext highlighter-rouge">deflate</code> extension
above and wrap its <code class="language-plaintext highlighter-rouge">incoming()</code> and <code class="language-plaintext highlighter-rouge">outgoing()</code> methods in two <code class="language-plaintext highlighter-rouge">Transform</code>
streams, producing this type:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>type Session = {
  incoming :: TransformStream
  outtoing :: TransformStream
  close    :: () -&gt; ()
}
</code></pre></div></div>

<p>The <code class="language-plaintext highlighter-rouge">Transform</code> class makes it easy to wrap an async function such that message
order is preserved:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">var</span> <span class="nx">stream</span>  <span class="o">=</span> <span class="nx">require</span><span class="p">(</span><span class="dl">'</span><span class="s1">stream</span><span class="dl">'</span><span class="p">),</span>
    <span class="nx">session</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">stream</span><span class="p">.</span><span class="nx">Transform</span><span class="p">({</span> <span class="na">objectMode</span><span class="p">:</span> <span class="kc">true</span> <span class="p">});</span>

<span class="nx">session</span><span class="p">.</span><span class="nx">_transform</span> <span class="o">=</span> <span class="kd">function</span><span class="p">(</span><span class="nx">message</span><span class="p">,</span> <span class="nx">_</span><span class="p">,</span> <span class="nx">callback</span><span class="p">)</span> <span class="p">{</span>
  <span class="kd">var</span> <span class="nb">self</span> <span class="o">=</span> <span class="k">this</span><span class="p">;</span>
  <span class="nx">deflate</span><span class="p">.</span><span class="nx">outgoing</span><span class="p">(</span><span class="nx">message</span><span class="p">,</span> <span class="kd">function</span><span class="p">(</span><span class="nx">error</span><span class="p">,</span> <span class="nx">result</span><span class="p">)</span> <span class="p">{</span>
    <span class="nb">self</span><span class="p">.</span><span class="nx">push</span><span class="p">(</span><span class="nx">result</span><span class="p">);</span>
    <span class="nx">callback</span><span class="p">();</span>
  <span class="p">});</span>
<span class="p">};</span>
</code></pre></div></div>

<p>However, this has a negative impact on throughput: it works by deferring
<code class="language-plaintext highlighter-rouge">callback()</code> until the async function has ‘returned’, which blocks <code class="language-plaintext highlighter-rouge">Transform</code>
from passing further input into the <code class="language-plaintext highlighter-rouge">_transform()</code> method until the current
message is dealt with completely. This would prevent sessions from processing
messages concurrently, and would unnecessarily reduce the throughput of
stateless extensions.</p>

<p>So, input should be handed off to sessions as soon as possible, and all we need
is a mechanism to reorder the output so that message order is preserved for the
next session in line.</p>

<h2 id="solution">Solution</h2>

<p>We now describe the model implemented here and how it meets the above design
goals. The above diagram where a stack of extensions sit between the driver and
application describes the data flow, but not the object graph. That looks like
this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>        +--------+
        | Driver |
        +---o----+
            |
            V
      +------------+      +----------+
      | Extensions o-----&gt;| Pipeline |
      +------------+      +-----o----+
                                |
                +---------------+---------------+
                |               |               |
          +-----o----+    +-----o----+    +-----o----+
          | Cell [A] |    | Cell [B] |    | Cell [C] |
          +----------+    +----------+    +----------+
</code></pre></div></div>

<p>A driver using this framework holds an instance of the <code class="language-plaintext highlighter-rouge">Extensions</code> class, which
it uses to register extension plugins, negotiate headers and transform messages.
The <code class="language-plaintext highlighter-rouge">Extensions</code> instance itself holds a <code class="language-plaintext highlighter-rouge">Pipeline</code>, which contains an array of
<code class="language-plaintext highlighter-rouge">Cell</code> objects, each of which wraps one of the sessions.</p>

<h3 id="message-processing">Message processing</h3>

<p>Both the <code class="language-plaintext highlighter-rouge">Pipeline</code> and <code class="language-plaintext highlighter-rouge">Cell</code> classes have <code class="language-plaintext highlighter-rouge">incoming()</code> and <code class="language-plaintext highlighter-rouge">outgoing()</code>
methods; the <code class="language-plaintext highlighter-rouge">Pipeline</code> interface pushes messages into the pipe, delegates the
message to each <code class="language-plaintext highlighter-rouge">Cell</code> in turn, then returns it back to the driver. Outgoing
messages pass through <code class="language-plaintext highlighter-rouge">A</code> then <code class="language-plaintext highlighter-rouge">B</code> then <code class="language-plaintext highlighter-rouge">C</code>, and incoming messages in the
reverse order.</p>

<p>Internally, a <code class="language-plaintext highlighter-rouge">Cell</code> contains two <code class="language-plaintext highlighter-rouge">Functor</code> objects. A <code class="language-plaintext highlighter-rouge">Functor</code> wraps an async
function and makes sure its output messages maintain the order of its input
messages. This name is due to <a href="https://github.com/fronx">@fronx</a>, on the basis
that, by preserving message order, the abstraction preserves the <em>mapping</em>
between input and output messages. To use our simple <code class="language-plaintext highlighter-rouge">deflate</code> extension from
above:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">var</span> <span class="nx">functor</span> <span class="o">=</span> <span class="k">new</span> <span class="nx">Functor</span><span class="p">(</span><span class="nx">deflate</span><span class="p">,</span> <span class="dl">'</span><span class="s1">outgoing</span><span class="dl">'</span><span class="p">);</span>

<span class="nx">functor</span><span class="p">.</span><span class="nx">call</span><span class="p">({</span> <span class="na">data</span><span class="p">:</span> <span class="nx">large</span> <span class="p">},</span> <span class="kd">function</span><span class="p">()</span> <span class="p">{</span>
  <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="dl">'</span><span class="s1">large</span><span class="dl">'</span><span class="p">);</span>
<span class="p">});</span>

<span class="nx">functor</span><span class="p">.</span><span class="nx">call</span><span class="p">({</span> <span class="na">data</span><span class="p">:</span> <span class="nx">small</span> <span class="p">},</span> <span class="kd">function</span><span class="p">()</span> <span class="p">{</span>
  <span class="nx">console</span><span class="p">.</span><span class="nx">log</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="dl">'</span><span class="s1">small</span><span class="dl">'</span><span class="p">);</span>
<span class="p">});</span>

<span class="cm">/*  -&gt;  1 'large'
        2 'small' */</span>
</code></pre></div></div>

<p>A <code class="language-plaintext highlighter-rouge">Cell</code> contains two of these, one for each direction:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                        +-----------------------+
                  +----&gt;| Functor [A, incoming] |
+----------+      |     +-----------------------+
| Cell [A] o------+
+----------+      |     +-----------------------+
                  +----&gt;| Functor [A, outgoing] |
                        +-----------------------+
</code></pre></div></div>

<p>This satisfies the message transformation requirements: the <code class="language-plaintext highlighter-rouge">Pipeline</code> simply
loops over the cells in the appropriate direction to transform each message.
Because each <code class="language-plaintext highlighter-rouge">Cell</code> will preserve message order, we can pass a message to the
next <code class="language-plaintext highlighter-rouge">Cell</code> in line as soon as the current <code class="language-plaintext highlighter-rouge">Cell</code> returns it. This gives each
<code class="language-plaintext highlighter-rouge">Cell</code> all the messages in order while maximising throughput.</p>

<h3 id="session-closing">Session closing</h3>

<p>We want to close each session as soon as possible, after all existing messages
have drained. To do this, each <code class="language-plaintext highlighter-rouge">Cell</code> begins with a pending message counter in
each direction, labelled <code class="language-plaintext highlighter-rouge">in</code> and <code class="language-plaintext highlighter-rouge">out</code> below.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                          +----------+
                          | Pipeline |
                          +-----o----+
                                |
                +---------------+---------------+
                |               |               |
          +-----o----+    +-----o----+    +-----o----+
          | Cell [A] |    | Cell [B] |    | Cell [C] |
          +----------+    +----------+    +----------+
             in: 0           in: 0           in: 0
            out: 0          out: 0          out: 0
</code></pre></div></div>

<p>When a message <em>m1</em> enters the pipeline, say in the <code class="language-plaintext highlighter-rouge">outgoing</code> direction, we
increment the <code class="language-plaintext highlighter-rouge">pending.out</code> counter on all cells immediately.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                          +----------+
                    m1 =&gt; | Pipeline |
                          +-----o----+
                                |
                +---------------+---------------+
                |               |               |
          +-----o----+    +-----o----+    +-----o----+
          | Cell [A] |    | Cell [B] |    | Cell [C] |
          +----------+    +----------+    +----------+
             in: 0           in: 0           in: 0
            out: 1          out: 1          out: 1
</code></pre></div></div>

<p><em>m1</em> is handed off to <code class="language-plaintext highlighter-rouge">A</code>, meanwhile a second message <code class="language-plaintext highlighter-rouge">m2</code> arrives in the same
direction. All <code class="language-plaintext highlighter-rouge">pending.out</code> counters are again incremented.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                          +----------+
                    m2 =&gt; | Pipeline |
                          +-----o----+
                                |
                +---------------+---------------+
            m1  |               |               |
          +-----o----+    +-----o----+    +-----o----+
          | Cell [A] |    | Cell [B] |    | Cell [C] |
          +----------+    +----------+    +----------+
             in: 0           in: 0           in: 0
            out: 2          out: 2          out: 2
</code></pre></div></div>

<p>When the first cell’s <code class="language-plaintext highlighter-rouge">A.outgoing</code> functor finishes processing <em>m1</em>, the first
<code class="language-plaintext highlighter-rouge">pending.out</code> counter is decremented and <em>m1</em> is handed off to cell <code class="language-plaintext highlighter-rouge">B</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                          +----------+
                          | Pipeline |
                          +-----o----+
                                |
                +---------------+---------------+
            m2  |           m1  |               |
          +-----o----+    +-----o----+    +-----o----+
          | Cell [A] |    | Cell [B] |    | Cell [C] |
          +----------+    +----------+    +----------+
             in: 0           in: 0           in: 0
            out: 1          out: 2          out: 2
</code></pre></div></div>

<p>As <code class="language-plaintext highlighter-rouge">B</code> finishes with <em>m1</em>, and as <code class="language-plaintext highlighter-rouge">A</code> finishes with <em>m2</em>, the <code class="language-plaintext highlighter-rouge">pending.out</code>
counters continue to decrement.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                          +----------+
                          | Pipeline |
                          +-----o----+
                                |
                +---------------+---------------+
                |           m2  |           m1  |
          +-----o----+    +-----o----+    +-----o----+
          | Cell [A] |    | Cell [B] |    | Cell [C] |
          +----------+    +----------+    +----------+
             in: 0           in: 0           in: 0
            out: 0          out: 1          out: 2
</code></pre></div></div>

<p>Say <code class="language-plaintext highlighter-rouge">C</code> is a little slow, and begins processing <em>m2</em> while still processing
<em>m1</em>. That’s fine, the <code class="language-plaintext highlighter-rouge">Functor</code> mechanism will keep <em>m1</em> ahead of <em>m2</em> in the
output.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                          +----------+
                          | Pipeline |
                          +-----o----+
                                |
                +---------------+---------------+
                |               |           m2  | m1
          +-----o----+    +-----o----+    +-----o----+
          | Cell [A] |    | Cell [B] |    | Cell [C] |
          +----------+    +----------+    +----------+
             in: 0           in: 0           in: 0
            out: 0          out: 0          out: 2
</code></pre></div></div>

<p>Once all messages are dealt with, the counters return to <code class="language-plaintext highlighter-rouge">0</code>.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                          +----------+
                          | Pipeline |
                          +-----o----+
                                |
                +---------------+---------------+
                |               |               |
          +-----o----+    +-----o----+    +-----o----+
          | Cell [A] |    | Cell [B] |    | Cell [C] |
          +----------+    +----------+    +----------+
             in: 0           in: 0           in: 0
            out: 0          out: 0          out: 0
</code></pre></div></div>

<p>The same process applies in the <code class="language-plaintext highlighter-rouge">incoming</code> direction, the only difference being
that messages are passed to <code class="language-plaintext highlighter-rouge">C</code> first.</p>

<p>This makes closing the sessions quite simple. When the driver wants to close the
socket, it calls <code class="language-plaintext highlighter-rouge">Pipeline.close()</code>. This <em>immediately</em> calls <code class="language-plaintext highlighter-rouge">close()</code> on all
the cells. If a cell has <code class="language-plaintext highlighter-rouge">in == out == 0</code>, then it immediately calls
<code class="language-plaintext highlighter-rouge">session.close()</code>. Otherwise, it stores the closing call and defers it until
<code class="language-plaintext highlighter-rouge">in</code> and <code class="language-plaintext highlighter-rouge">out</code> have both ticked down to zero. The pipeline will not accept new
messages after <code class="language-plaintext highlighter-rouge">close()</code> has been called, so we know the pending counts will not
increase after this point.</p>

<p>This means each session is closed as soon as possible: <code class="language-plaintext highlighter-rouge">A</code> can close while the
slow <code class="language-plaintext highlighter-rouge">C</code> session is still working, because it knows there are no more messages
on the way. Similarly, <code class="language-plaintext highlighter-rouge">C</code> will defer closing if <code class="language-plaintext highlighter-rouge">close()</code> is called while <em>m1</em>
is still in <code class="language-plaintext highlighter-rouge">B</code>, and <em>m2</em> in <code class="language-plaintext highlighter-rouge">A</code>, because its pending count means it knows it
has work yet to do, even if it’s not received those messages yet. This concern
cannot be addressed by extensions acting only on their own local state, unless
we pollute individual extensions by making them all implement this same
mechanism.</p>

<p>The actual closing API at each level is slightly different:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>type Session = {
  close :: () -&gt; ()
}

type Cell = {
  close :: () -&gt; Promise ()
}

type Pipeline = {
  close :: Callback -&gt; ()
}
</code></pre></div></div>

<p>This might appear inconsistent so it’s worth explaining. Remember that a
<code class="language-plaintext highlighter-rouge">Pipeline</code> holds a list of <code class="language-plaintext highlighter-rouge">Cell</code> objects, each wrapping a <code class="language-plaintext highlighter-rouge">Session</code>. The driver
talks (via the <code class="language-plaintext highlighter-rouge">Extensions</code> API) to the <code class="language-plaintext highlighter-rouge">Pipeline</code> interface, and it wants
<code class="language-plaintext highlighter-rouge">Pipeline.close()</code> to do two things: close all the sessions, and tell me when
it’s safe to start the closing procedure (i.e. when all messages have drained
from the pipe and been handed off to the application or socket). A callback API
works well for that.</p>

<p>At the other end of the stack, <code class="language-plaintext highlighter-rouge">Session.close()</code> is a nullary void method with
no callback or promise API because we don’t care what it does, and whatever it
does do will not block the WebSocket protocol; we’re not going to hold off
processing messages while a session closes its de/compression context. We just
tell it to close itself, and don’t want to wait while it does that.</p>

<p>In the middle, <code class="language-plaintext highlighter-rouge">Cell.close()</code> returns a promise rather than using a callback.
This is for two reasons. First, <code class="language-plaintext highlighter-rouge">Cell.close()</code> might not do anything
immediately, it might have to defer its effect while messages drain. So, if
given a callback, it would have to store it in a queue for later execution.
Callbacks work fine if your method does something and can then invoke the
callback itself, but if you need to store callbacks somewhere so another method
can execute them, a promise is a better fit. Second, it better serves the
purposes of <code class="language-plaintext highlighter-rouge">Pipeline.close()</code>: it wants to call <code class="language-plaintext highlighter-rouge">close()</code> on each of a list of
cells, and wait for all of them to finish. This is simple and idiomatic using
promises:</p>

<div class="language-js highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">var</span> <span class="nx">closed</span> <span class="o">=</span> <span class="nx">cells</span><span class="p">.</span><span class="nx">map</span><span class="p">((</span><span class="nx">cell</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="nx">cell</span><span class="p">.</span><span class="nx">close</span><span class="p">());</span>
<span class="nb">Promise</span><span class="p">.</span><span class="nx">all</span><span class="p">(</span><span class="nx">closed</span><span class="p">).</span><span class="nx">then</span><span class="p">(</span><span class="nx">callback</span><span class="p">);</span>
</code></pre></div></div>

<p>(We don’t actually use a full <em>Promises/A+</em> compatible promise here, we use a
much simplified construction that acts as a callback aggregater and resolves
synchronously and does not support chaining, but the principle is the same.)</p>

<h3 id="error-handling">Error handling</h3>

<p>We’ve not mentioned error handling so far but it bears some explanation. The
above counter system still applies, but behaves slightly differently in the
presence of errors.</p>

<p>Say we push three messages into the pipe in the outgoing direction:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                          +----------+
            m3, m2, m1 =&gt; | Pipeline |
                          +-----o----+
                                |
                +---------------+---------------+
                |               |               |
          +-----o----+    +-----o----+    +-----o----+
          | Cell [A] |    | Cell [B] |    | Cell [C] |
          +----------+    +----------+    +----------+
             in: 0           in: 0           in: 0
            out: 3          out: 3          out: 3
</code></pre></div></div>

<p>They pass through the cells successfully up to this point:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                          +----------+
                          | Pipeline |
                          +-----o----+
                                |
                +---------------+---------------+
            m3  |           m2  |           m1  |
          +-----o----+    +-----o----+    +-----o----+
          | Cell [A] |    | Cell [B] |    | Cell [C] |
          +----------+    +----------+    +----------+
             in: 0           in: 0           in: 0
            out: 1          out: 2          out: 3
</code></pre></div></div>

<p>At this point, session <code class="language-plaintext highlighter-rouge">B</code> produces an error while processing <em>m2</em>, that is <em>m2</em>
becomes <em>e2</em>. <em>m1</em> is still in the pipeline, and <em>m3</em> is queued behind <em>m2</em>.
What ought to happen is that <em>m1</em> is handed off to the socket, then <em>m2</em> is
released to the driver, which will detect the error and begin closing the
socket. No further processing should be done on <em>m3</em> and it should not be
released to the driver after the error is emitted.</p>

<p>To handle this, we allow errors to pass down the pipeline just like messages do,
to maintain ordering. But, once a cell sees its session produce an error, or it
receives an error from upstream, it should refuse to accept any further
messages. Session <code class="language-plaintext highlighter-rouge">B</code> might have begun processing <em>m3</em> by the time it produces
the error <em>e2</em>, but <code class="language-plaintext highlighter-rouge">C</code> will have been given <em>e2</em> before it receives <em>m3</em>, and
can simply drop <em>m3</em>.</p>

<p>Now, say <em>e2</em> reaches the slow session <code class="language-plaintext highlighter-rouge">C</code> while <em>m1</em> is still present,
meanwhile <em>m3</em> has been dropped. <code class="language-plaintext highlighter-rouge">C</code> will never receive <em>m3</em> since it will have
been dropped upstream. Under the present model, its <code class="language-plaintext highlighter-rouge">out</code> counter will be <code class="language-plaintext highlighter-rouge">3</code>
but it is only going to emit two more values: <em>m1</em> and <em>e2</em>. In order for
closing to work, we need to decrement <code class="language-plaintext highlighter-rouge">out</code> to reflect this. The situation
should look like this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>                          +----------+
                          | Pipeline |
                          +-----o----+
                                |
                +---------------+---------------+
                |               |           e2  | m1
          +-----o----+    +-----o----+    +-----o----+
          | Cell [A] |    | Cell [B] |    | Cell [C] |
          +----------+    +----------+    +----------+
             in: 0           in: 0           in: 0
            out: 0          out: 0          out: 2
</code></pre></div></div>

<p>When a cell sees its session emit an error, or when it receives an error from
upstream, it sets its pending count in the appropriate direction to equal the
number of messages it is <em>currently</em> processing. It will not accept any messages
after it sees the error, so this will allow the counter to reach zero.</p>

<p>Note that while <em>e2</em> is in the pipeline, <code class="language-plaintext highlighter-rouge">Pipeline</code> should drop any further
messages in the outgoing direction, but should continue to accept incoming
messages. Until <em>e2</em> makes it out of the pipe to the driver, behind previous
successful messages, the driver does not know an error has happened, and a
message may arrive over the socket and make it all the way through the incoming
pipe in the meantime. We only halt processing in the affected direction to avoid
doing unnecessary work since messages arriving after an error should not be
processed.</p>

<p>Some unnecessary work may happen, for example any messages already in the
pipeline following <em>m2</em> will be processed by <code class="language-plaintext highlighter-rouge">A</code>, since it’s upstream of the
error. Those messages will be dropped by <code class="language-plaintext highlighter-rouge">B</code>.</p>

<h2 id="alternative-ideas">Alternative ideas</h2>

<p>I am considering implementing <code class="language-plaintext highlighter-rouge">Functor</code> as an object-mode transform stream
rather than what is essentially an async function. Being object-mode, a stream
would preserve message boundaries and would also possibly help address
back-pressure. I’m not sure whether this would require external API changes so
that such streams could be connected to the downstream driver’s streams.</p>

<h2 id="acknowledgements">Acknowledgements</h2>

<p>Credit is due to <a href="https://github.com/mnowster">@mnowster</a> for helping with the
design and to <a href="https://github.com/fronx">@fronx</a> for helping name things.</p>


      
    </div>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/anchor-js/4.1.0/anchor.min.js" integrity="sha256-lZaRhKri35AyJSypXXs4o6OPFTbTmUoltBbDCbdzegg=" crossorigin="anonymous"></script>
    <script>anchors.add();</script>
  </body>
</html>
